<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Regulación Global de IA</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="regulaciones.css">
</head>
<body class="text-gray-800">
    <div class="container mx-auto p-4 md:p-8">
        <!-- Header Section -->
        <header class="text-center mb-8 sm:mb-12">
            <h1 class="text-3xl sm:text-4xl md:text-5xl font-bold text-gray-900 mb-2">Panorama Global de <span class="text-blue-600">Regulación de IA</span></h1>
            <p class="text-base sm:text-lg text-gray-600 max-w-3xl mx-auto px-4">Resumen de los marcos regulatorios y tendencias internacionales en la gobernanza de la inteligencia artificial.</p>
            <div class="mt-4 space-x-2">
                <a href="index.html" class="inline-block bg-blue-600 text-white px-5 py-2 rounded-lg font-semibold shadow hover:bg-blue-700 transition">Volver al Análisis de AI Company</a>
                <a href="tendencias-ia.html" class="inline-block bg-indigo-600 text-white px-5 py-2 rounded-lg font-semibold shadow hover:bg-indigo-700 transition">Ver Tendencias IA 2025</a>
                <a href="tendencias-usuario.html" class="inline-block bg-green-600 text-white px-5 py-2 rounded-lg font-semibold shadow hover:bg-green-700 transition">Ver Tendencias de Usuario IA</a>
            </div>
        </header>
        <!-- Secciones de contenido -->
        <section class="mb-12">
            <h2 class="text-2xl sm:text-3xl font-bold text-center mb-8">Unión Europea: AI Act</h2>
            <div class="card p-6 mb-6">
                <ul class="list-disc list-inside text-gray-700 space-y-2">
                    <li>Regulación integral basada en el riesgo, pionera a nivel global.</li>
                    <li><strong>Prohibiciones y requisitos:</strong> Prohíbe usos inaceptables (social scoring, reconocimiento biométrico en tiempo real). Sistemas de alto riesgo requieren transparencia, gestión de riesgos, supervisión humana y evaluaciones de conformidad.</li>
                    <li><strong>Sanciones:</strong> Multas de hasta el 6% de la facturación anual global o 30-35 millones de euros.</li>
                    <li><strong>Implementación:</strong> Por fases. Desde agosto 2025, requisitos para modelos GPAI (informes de incidentes, documentación técnica). Código de Prácticas GPAI esperado en agosto 2025.</li>
                </ul>
            </div>
        </section>
        <section class="mb-12">
            <h2 class="text-2xl sm:text-3xl font-bold text-center mb-8">Estados Unidos: Un Enfoque Fragmentado</h2>
            <div class="card p-6 mb-6">
                <ul class="list-disc list-inside text-gray-700 space-y-2">
                    <li>No existe una ley federal vinculante específica para IA; predominan regulaciones estatales y propuestas federales.</li>
                    <li><strong>Iniciativas federales:</strong> "Winning the Race: America's AI Action Plan" (julio 2025) y AI Safety Act (auditorías obligatorias para sistemas con +10M usuarios, prohibición de reconocimiento facial policial sin orden judicial).</li>
                </ul>
                <h3 class="font-bold text-lg mt-6 mb-2">Regulaciones estatales destacadas:</h3>
                <ul class="list-disc list-inside text-gray-700 space-y-1">
                    <li><strong>Texas:</strong> Responsible AI Governance Act (TRAIGA 2.0): evaluaciones de impacto algorítmico y explicaciones al consumidor.</li>
                    <li><strong>California:</strong> AI Transparency Act (enero 2026): plataformas de alto tráfico deben revelar contenido generado por IA.</li>
                    <li><strong>Nueva York:</strong> Obligación de reportar despidos relacionados con IA bajo la WARN Act.</li>
                </ul>
            </div>
        </section>
        <section class="mb-12">
            <h2 class="text-2xl sm:text-3xl font-bold text-center mb-8">Regulaciones en el Resto del Mundo</h2>
            <div class="card p-6 mb-6">
                <ul class="list-disc list-inside text-gray-700 space-y-2">
                    <li><strong>Corea del Sur:</strong> Enmienda a la Basic Act on AI: divulgación de conjuntos de datos usados en IA generativa.</li>
                    <li><strong>Vietnam:</strong> Ley para IA de alto riesgo e imposición de licencias.</li>
                    <li><strong>Singapur:</strong> Expansión de Cyber Essentials para seguridad en IA y nube (PYMEs).</li>
                    <li><strong>Hong Kong:</strong> Guía y checklist para IA generativa bajo ley de privacidad.</li>
                    <li><strong>Brasil:</strong> Marco regulatorio basado en riesgo, pendiente de promulgación final.</li>
                    <li><strong>Otros países:</strong> Indonesia, otros países de América Latina y África adoptan lineamientos alineados con OCDE y UE.</li>
                </ul>
            </div>
        </section>
        <section class="mb-12">
            <h2 class="text-2xl sm:text-3xl font-bold text-center mb-8">Iniciativas Internacionales</h2>
            <div class="card p-6 mb-6">
                <ul class="list-disc list-inside text-gray-700 space-y-2">
                    <li>China propuso en WAIC 2025 la creación de un organismo internacional de gobernanza de IA bajo la ONU para coordinar y establecer estándares comunes.</li>
                </ul>
            </div>
        </section>
        <section class="mb-12">
            <h2 class="text-2xl sm:text-3xl font-bold text-center mb-8">Implicaciones para Empresas</h2>
            <div class="card p-6 mb-6">
                <ul class="list-disc list-inside text-gray-700 space-y-2">
                    <li><strong>Exposición global y extraterritorialidad:</strong> Empresas pueden estar sujetas a normativas como la AI Act de la UE si atienden clientes en esos mercados.</li>
                    <li><strong>Exigencias para sistemas de alto riesgo:</strong> Scoring crediticio y biometría requieren auditoría, transparencia, supervisión humana y evaluación de impacto.</li>
                    <li><strong>Monitoreo regulatorio constante:</strong> Es clave vigilar regulaciones estatales en EE.UU. (Texas, California) que avanzan más rápido que la legislación federal.</li>
                    <li><strong>Deber de transparencia y reporte:</strong> Obligación de informar a usuarios sobre IA, reportar despidos automatizados y declarar conjuntos de datos usados.</li>
                    <li><strong>Responsabilidad y ética:</strong> Gobernanza explícita, gestión de riesgos y alineación con derechos humanos son indispensables.</li>
                    <li><strong>Oportunidades estratégicas:</strong> Participar en sandboxes regulatorios, adherirse a códigos voluntarios o buscar certificaciones para innovar de forma segura y competitiva.</li>
                </ul>
            </div>
        </section>
    </div>
</body>
</html>
